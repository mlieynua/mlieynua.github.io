---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}
[Detailed curriculum vitae is hereğŸ“„](https://docs.google.com/document/d/115ZlcvwP1xPHFDiRQSWOl2K1vKwX3DEo7miXUOsTQpw/edit?usp=sharing)

## Publications
### Preprints
* Yusuke Ide, Yuto Nishida, <u>Miyu Oba</u>, Yusuke Sakai, Justin Vasselli, Hidetaka Kamigaito, Taro Watanabe. "How to Make the Most of LLMs' Grammatical Knowledge for Acceptability Judgments" \[ [arXiv](https://arxiv.org/abs/2408.09639) \]
* Shintaro Ozaki, Kazuki Hayashi, <u>Miyu Oba</u>, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe. "BQA: Body Language Question Answering Dataset for Video Large Language Models" \[ [arXiv](https://arxiv.org/abs/2410.13206) \]

### International Conference
* Akari Haga, Akiyo Fukatsu, <u>Miyu Oba</u>, Arianna Bisazza, Yohei Oseki. "BabyLM Challenge: Exploring the Effect of Variation Sets on Language Model Training Efficiency" the BabyLM Challenge at the 28th Conference on Computational Natural Language Learning, 2024/11 \[ Outstanding paper award \] \[paper \| [arXiv](https://arxiv.org/abs/2411.09587) \]
* <u>Miyu Oba</u>, Yohei Oseki, Akiyo Fukatsu, Akari Haga, Hiroki Ouchi, Taro Watanabe, Saku Sugawara. "Can Language Models Induce Grammatical Knowledge from Indirect Evidence?" Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP-2024, Main, long), 2024/11  \[[paper](https://aclanthology.org/2024.emnlp-main.1146/) \| [arXiv](https://arxiv.org/abs/2410.06022) \]
* Akari Haga, Saku Sugawara, Akiyo Fukatsu, <u>Miyu Oba</u>, Hiroki Ouchi, Taro Watanabe, Yohei Oseki. "Modeling Overregularization in Children with Small Language Models." Findings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL-2024, Findings, long), 2024/08. \[[paper](https://aclanthology.org/2024.findings-acl.865/) \| arXiv\]
* <u>Miyu Oba</u>, Akari Haga, Akiyo Fukatsu, Yohei Oseki. "BabyLM Challenge: Curriculum learning based on sentence complexity approximating language acquisition", the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning, 2023/12. \[[paper](https://aclanthology.org/2023.conll-babylm.25/) \| arXiv\]
* <u>Miyu Oba</u>, Tatsuki Kuribayashi, Hiroki Ouchi, Taro Watanabe. "Second Language Acquisition of Neural Language Models." Findings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL-2023, Findings, long), 2023/07. \[[paper](https://aclanthology.org/2023.findings-acl.856/) \| [arXiv](https://arxiv.org/abs/2306.02920)\]

### Journal
* å¤§ç¾½æœªæ‚ , æ —æ—æ¨¹ç”Ÿ, å¤§å†…å•“æ¨¹, æ¸¡è¾ºå¤ªéƒ. è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç¬¬äºŒè¨€èªç²å¾—. è‡ªç„¶è¨€èªå‡¦ç† (domestic journal), Volume 31, Number 2, pp.433-455,  2024/06. \[[paper](https://doi.org/10.5715/jnlp.31.433)\]


### Domestic Conference
* å°¾å´ æ…å¤ªéƒ, æ— å’Œæ¨¹, <u>å¤§ç¾½ æœªæ‚ </u>, å‚äº• å„ªä»‹, ä¸Šå£å¤– è‹±å‰›, æ¸¡è¾º å¤ªéƒ. ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯éè¨€èªã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç†è§£ã—ã¦ã„ã‚‹ã‹ï¼Ÿ. ç¬¬19å›NLPè‹¥æ‰‹ã®ä¼š ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ  (YANS), 2024/09. \[ Encouragement Award (å¥¨åŠ±è³) received to 1st author \]
* äº•æ‰‹ä½‘ç¿¼, è¥¿ç”°æ‚ äºº, <u>å¤§ç¾½æœªæ‚ </u>, å‚äº•å„ªä»‹, Justin Vasselli, æ¸¡è¾ºå¤ªéƒ, ä¸Šå£å¤–è‹±å‰›. å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«é©ã—ãŸå®¹èªæ€§åˆ¤æ–­æ‰‹æ³•ã®æ¤œè¨. ç¬¬260å›è‡ªç„¶è¨€èªå‡¦ç†ç ”ç©¶ä¼š, 8pages, 2024/06. \[ Young Researcher Award (è‹¥æ‰‹å¥¨åŠ±è³) received to 1st author \] \[[paper](http://id.nii.ac.jp/1001/00234977/)\]
* <u>å¤§ç¾½æœªæ‚ </u>, å¤§é–¢æ´‹å¹³, æ·±æ´¥è¡ä¸–, èŠ³è³€ã‚ã‹ã‚Š, å¤§å†…å•“æ¨¹, æ¸¡è¾ºå¤ªéƒ, è…åŸæœ”. è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ–‡æ³•çŸ¥è­˜è©•ä¾¡ã«ãŠã‘ã‚‹é–“æ¥è‚¯å®šè¨¼æ‹ ã®åˆ†æ. è¨€èªå‡¦ç†å­¦ä¼šç¬¬30å›å¹´æ¬¡å¤§ä¼š, 4pages, 2024/3. \[[paper](https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/E10-5.pdf)\]
* èŠ³è³€ã‚ã‹ã‚Š, è…åŸæœ”, æ·±æ´¥è¡ä¸–, <u>å¤§ç¾½æœªæ‚ </u>, å¤§å†…å•“æ¨¹, æ¸¡è¾ºå¤ªéƒ, å¤§é–¢æ´‹å¹³. å°è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹å­ä¾›ã®éå‰°ä¸€èˆ¬åŒ–ã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°. è¨€èªå‡¦ç†å­¦ä¼šç¬¬30å›å¹´æ¬¡å¤§ä¼š, 4pages, 2024/3. \[[paper](https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/E9-1.pdf)\]
* <u>å¤§ç¾½æœªæ‚ </u>, èŠ³è³€ã‚ã‹ã‚Š, æ·±æ´¥è¡ä¸–, å¤§é–¢æ´‹å¹³. è¨€èªç²å¾—éç¨‹ã‚’æ¨¡å€£ã—ãŸæ–‡ã®è¤‡é›‘ã•ã«åŸºã¥ãã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ å­¦ç¿’. ç¬¬18å›NLPè‹¥æ‰‹ã®ä¼š ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ  (YANS), 2023/08.
* <u>å¤§ç¾½æœªæ‚ </u>, æ —æ—æ¨¹ç”Ÿ, å¤§å†…å•“æ¨¹, æ¸¡è¾ºå¤ªéƒ. è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç¬¬äºŒè¨€èªç²å¾—. è¨€èªå‡¦ç†å­¦ä¼šç¬¬29å›å¹´æ¬¡å¤§ä¼š, 4pages, 2023/3. \[ <u>Young Researcher Award (è‹¥æ‰‹å¥¨åŠ±è³)<\u> \] \[[paper](https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/D3-1.pdf)\]
* <u>å¤§ç¾½æœªæ‚ </u>, æ —æ—æ¨¹ç”Ÿ, å¤§å†…å•“æ¨¹, æ¸¡è¾ºå¤ªéƒ. è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç¬¬äºŒè¨€èªç²å¾—åŠ¹ç‡. ç¬¬254å›è‡ªç„¶è¨€èªå‡¦ç†ç ”ç©¶ä¼š, 6pages, 2022/11. \[ IPSJ Yamashita SIG Research Award (å±±ä¸‹è¨˜å¿µç ”ç©¶è³),Best Paper Award (å„ªç§€ç ”ç©¶è³) \] \[[paper](http://id.nii.ac.jp/1001/00222493/)\]
* <u>å¤§ç¾½æœªæ‚ </u>, æ —æ—æ¨¹ç”Ÿ, å¤§å†…å•“æ¨¹, æ¸¡è¾ºå¤ªéƒ. è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç¬¬äºŒè¨€èªç²å¾—åŠ¹ç‡. ç¬¬17å›NLPè‹¥æ‰‹ã®ä¼š ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ  (YANS), 2022/08. \[ Encouragement Award (å¥¨åŠ±è³) \]

## Education
* 2024/04-present: Doctor of Engineering, Division of Information Science, NARA Institute of Science and Technology
  * Research on natural language processing, computational (psycho)linguistics
* 2023/04-2024/03: Master of Engineering, Division of Information Science, NARA Institute of Science and Technology
  * Research on natural language processing, computational (psycho)linguistics
* 2018/04-2022/03: Bachelor of Foreign Studies, Department of French Studies, Nanzan University
  * Study of linguistics and french culture
* 2015/04-2018/03: High School Diploma, Meiwa High School

## Experiences
* 2024/10-: Guest Researcher
  * University of GÃ¶ttingen, Germany
  * Supervisor: [Lisa Beinborn](https://beinborn.eu/)
  * Modeling cognitive processing targeting on

* 2023/04-: Research Assistant
  * National Institute of Informatics
  * Supervisor: [Saku Sugawara](https://penzant.net/)
  * Survey papers on Linguistics and Cognitive science related to Natural language processing
  * Research on language acquisition of language models inspired by human language acquisition

* 2022/08-2023/01: Natural Language Processing R&D Engineer
  * Trustworthy AI team, LINE Corp.
  * Work on Ethics for NLP
  * Survey and implement evaluation methods for fairness of language models

* 2020/06-2022/03: Data Scientist
  * ROX Inc.
  * Demand forecasting, data analysis in the logistics and retail sectors
  * Development of applications leveraging forecast data

## Grants
* 2025/04-: Research Fellowship for Young Scientists by Japan Society for the Promotion of Science (PhD Fellowship; DC2)
* 2024/11: Scholarship for Study aboroad by the Association for Natural Language Processing
* 2024/04-Present: NAIST Granite Program (PhD Fellowship; JST SPRING)
* 2022/04-2024/03: JASSO Scholarship: Full Repayment exemption due to outstanding achievements (ç‰¹ã«å„ªã‚ŒãŸæ¥­ç¸¾ã«ã‚ˆã‚‹å…¨é¡è¿”æ¸ˆå…é™¤)
* 2023/07: ACL SRW Travel Grants
  
## Activities/Talks/Interviews
* 2023/08: Present the highly intersted research ["How to Plant Trees in Language Models: Data and Architectural Effects on the Emergence of Syntactic Inductive Biases"](https://aclanthology.org/2023.acl-long.629/) at æœ€å…ˆç«¯NLPå‹‰å¼·ä¼š \[[slides](https://speakerdeck.com/miyuoba/zui-xian-duan-nlpmian-qiang-hui-2023/)\]
* 2023/03: Graduate student interview with Gender Equality Promotion Office \[[page](http://www.naist.jp/gender/contents/message/student_interview/minority_01_en.html)\]
* 2023/03: è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç¬¬äºŒè¨€èªç²å¾— -ç ”ç©¶ã®ãã£ã‹ã‘ã¨ã“ã‚Œã‹ã‚‰-. è¨€èªå‡¦ç†å­¦ä¼šç¬¬29å›å¹´æ¬¡å¤§ä¼šãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ— æ·±å±¤å­¦ç¿’æ™‚ä»£ã®è¨ˆç®—è¨€èªå­¦. \[[page](http://clml.ism.ac.jp/~daichi/workshop/2023-deepcl/)\]
* 2021/12: Fundamental Information Technology Engineer Examination (FE; åŸºæœ¬æƒ…å ±æŠ€è¡“è€…è©¦é¨“)
* 2020/12: JPHACKS2020 (Domestic Hackathon) \[ Finalists, NTT Resonant Award & Studio Arcana Award \]
* 2020/11: Call for Code2020 (International Hackathon) \[ Regional Finalists (æ—¥æœ¬ä¸Šä½4ä½) \]
* 2020/09: TOEIC 855
* 2020/06: Buildï¼ Mercari (Software Engineer Training Program)

## Reviewer
* 2024: ARR